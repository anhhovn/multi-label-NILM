{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b35281d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9dea48ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Dict, List\n",
    "from pandas import DataFrame \n",
    "import time\n",
    "from nilmtk import DataSet, MeterGroup\n",
    "import loguru\n",
    "from numba import njit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "from fuzzywuzzy import fuzz\n",
    "from enum import Enum\n",
    "from skmultilearn.adapt import MLkNN\n",
    "from skmultilearn.ensemble import RakelD\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from pyts import approximation, transformation\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "SITE_METER = 'Site meter'\n",
    "\n",
    "'''\n",
    "\n",
    "'''\n",
    "DEBUG: bool = True\n",
    "TIMING: bool = True\n",
    "TRACE_MEMORY: bool = True\n",
    "INFO: bool = True\n",
    "MB: int = 1024 * 1024\n",
    "classifier = MLkNN(ignore_first_neighbours=0, k=3, s=1.0)\n",
    "rakel = RakelD(MLPClassifier(hidden_layer_sizes=(100, 100, 100), learning_rate='adaptive',solver='adam'), labelset_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8e6a4f02",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Reading data from specified meters. \n",
      "-Building: 3\n",
      "-Appliances ['electric furnace', 'CE appliance', 'microwave', 'washer dryer', 'unknown', 'sockets']\n",
      "DEBUG:  read_selected_appliances ['electric furnace', 'CE appliance', 'microwave', 'washer dryer', 'unknown', 'sockets'], 3, 4-16-2011, 4-30-2011, True\n",
      "TIMING: NILMTK select using appliances: 0.03\n",
      "Loading data for meter ElecMeterID(instance=14, building=3, dataset='REDD')     \n",
      "Done loading data all meters for this chunk.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-08 12:23:14.410 | DEBUG    | __main__:setup_one_building:286 - Length of data of all loaded meters 200886\n",
      "2022-09-08 12:23:14.414 | DEBUG    | __main__:setup_one_building:288 - Length of data of all loaded meters 200886\n",
      "2022-09-08 12:23:14.415 | INFO     | __main__:create_multilabels_from_meters:229 - Creating multilabels from meter electric furnace, \n",
      "labels2id[col] ElecMeterID(instance=10, building=3, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=10, building=3, dataset='REDD', appliances=[Appliance(type='electric furnace', instance=1)])\n",
      "2022-09-08 12:23:14.416 | DEBUG    | __main__:create_multilabels_from_meters:239 - meters[col].values.astype(float) electric furnace - [0.  5.  4.5 ... 0.  0.  0. ]\n",
      "D:\\Users\\hdmav\\anaconda3\\envs\\nilmtk-env\\lib\\site-packages\\numba\\core\\typed_passes.py:329: NumbaPerformanceWarning: \u001b[1m\n",
      "The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible.\n",
      "\n",
      "To find out why, try turning on parallel diagnostics, see https://numba.readthedocs.io/en/stable/user/parallel.html#diagnostics for help.\n",
      "\u001b[1m\n",
      "File \"C:\\Users\\hdmav\\AppData\\Local\\Temp\\ipykernel_18148\\40441312.py\", line 247:\u001b[0m\n",
      "\u001b[1m@njit(parallel=True)\n",
      "\u001b[1mdef create_labels(array, threshold):\n",
      "\u001b[0m\u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaPerformanceWarning(msg,\n",
      "2022-09-08 12:23:14.564 | INFO     | __main__:create_multilabels_from_meters:229 - Creating multilabels from meter CE appliance, \n",
      "labels2id[col] ElecMeterID(instance=6, building=3, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=6, building=3, dataset='REDD', appliances=[Appliance(type='CE appliance', instance=1)])\n",
      "2022-09-08 12:23:14.566 | DEBUG    | __main__:create_multilabels_from_meters:239 - meters[col].values.astype(float) CE appliance - [  0.  125.5 125.5 ...   0.    0.    0. ]\n",
      "2022-09-08 12:23:14.572 | INFO     | __main__:create_multilabels_from_meters:229 - Creating multilabels from meter unknown, \n",
      "labels2id[col] ElecMeterID(instance=20, building=3, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=20, building=3, dataset='REDD', appliances=[Appliance(type='unknown', instance=1)])\n",
      "2022-09-08 12:23:14.575 | DEBUG    | __main__:create_multilabels_from_meters:239 - meters[col].values.astype(float) unknown - [0. 0. 0. ... 0. 0. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMING: NILMTK converting specified appliances to dataframe: 2.4\n",
      "DEBUG: Length of data of read_selected_appliances 200886\n",
      "\n",
      "\n",
      "READ_SELECTED_APPLIANCES: \n",
      "                           (10, 3, REDD)  (6, 3, REDD)  (20, 3, REDD)  \\\n",
      "2011-04-16 01:11:24-04:00            0.0           0.0            0.0   \n",
      "2011-04-16 01:11:30-04:00            5.0         125.5            0.0   \n",
      "2011-04-16 01:11:36-04:00            4.5         125.5            0.0   \n",
      "2011-04-16 01:11:42-04:00            5.0         127.0            0.0   \n",
      "2011-04-16 01:11:48-04:00            5.0         125.0            0.0   \n",
      "\n",
      "                           (16, 3, REDD)  (1, 3, REDD)  \\\n",
      "2011-04-16 01:11:24-04:00            0.0    180.850006   \n",
      "2011-04-16 01:11:30-04:00            2.0    181.331665   \n",
      "2011-04-16 01:11:36-04:00            2.0    180.809998   \n",
      "2011-04-16 01:11:42-04:00            2.0    181.523331   \n",
      "2011-04-16 01:11:48-04:00            2.0    180.893326   \n",
      "\n",
      "                           (((13, 3, REDD), (14, 3, REDD)),)  (3, 3, REDD)  \n",
      "2011-04-16 01:11:24-04:00                                0.0           0.0  \n",
      "2011-04-16 01:11:30-04:00                                0.0           1.5  \n",
      "2011-04-16 01:11:36-04:00                                0.0           1.5  \n",
      "2011-04-16 01:11:42-04:00                                0.0           1.5  \n",
      "2011-04-16 01:11:48-04:00                                0.0           2.0  \n",
      "INFO: Df columns before normalization Index([                      (10, 3, 'REDD'),\n",
      "                              (6, 3, 'REDD'),\n",
      "                             (20, 3, 'REDD'),\n",
      "                             (16, 3, 'REDD'),\n",
      "                              (1, 3, 'REDD'),\n",
      "       (((13, 3, 'REDD'), (14, 3, 'REDD')),),\n",
      "                              (3, 3, 'REDD')],\n",
      "      dtype='object')\n",
      "INFO: Labels before normalization ['Electric furnace', 'CE appliance', 'Unknown', 'Microwave', 'Site meter', 'Washer dryer', 'Sockets']\n",
      "INFO: electric furnace ~ Electric furnace (100%)\n",
      "INFO: CE appliance ~ CE appliance (100%)\n",
      "INFO: unknown ~ Unknown (100%)\n",
      "INFO: microwave ~ Microwave (100%)\n",
      "INFO: washer dryer ~ Washer dryer (100%)\n",
      "INFO: sockets ~ Sockets (100%)\n",
      "INFO: Normalized labels ['electric furnace', 'CE appliance', 'unknown', 'microwave', 'Site meter', 'washer dryer', 'sockets']\n",
      "INFO: Meters that have been loaded (all_df.columns):\n",
      "Index(['electric furnace', 'CE appliance', 'unknown', 'microwave',\n",
      "       'Site meter', 'washer dryer', 'sockets'],\n",
      "      dtype='object')\n",
      "threshold =  40\n",
      "threshold =  10\n",
      "threshold =  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-08 12:23:14.582 | INFO     | __main__:create_multilabels_from_meters:229 - Creating multilabels from meter microwave, \n",
      "labels2id[col] ElecMeterID(instance=16, building=3, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=16, building=3, dataset='REDD', appliances=[Appliance(type='microwave', instance=1)])\n",
      "2022-09-08 12:23:14.584 | DEBUG    | __main__:create_multilabels_from_meters:239 - meters[col].values.astype(float) microwave - [0. 2. 2. ... 0. 0. 0.]\n",
      "2022-09-08 12:23:14.590 | INFO     | __main__:create_multilabels_from_meters:229 - Creating multilabels from meter Site meter, \n",
      "labels2id[col] ElecMeterID(instance=1, building=3, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=1, building=3, dataset='REDD', site_meter, appliances=[])\n",
      "2022-09-08 12:23:14.592 | DEBUG    | __main__:create_multilabels_from_meters:237 - Skipping Site meter - [180.8500061  181.33166504 180.80999756 ...   0.           0.\n",
      "   0.        ]\n",
      "2022-09-08 12:23:14.594 | INFO     | __main__:create_multilabels_from_meters:229 - Creating multilabels from meter washer dryer, \n",
      "labels2id[col] MeterGroupID(meters=(ElecMeterID(instance=13, building=3, dataset='REDD'), ElecMeterID(instance=14, building=3, dataset='REDD')))\n",
      "metergroup[labels2id[col]] MeterGroup(meters=\n",
      "  ElecMeter(instance=13, building=3, dataset='REDD', appliances=[Appliance(type='washer dryer', instance=1)])\n",
      "  ElecMeter(instance=14, building=3, dataset='REDD', appliances=[Appliance(type='washer dryer', instance=1)])\n",
      ")\n",
      "2022-09-08 12:23:14.595 | DEBUG    | __main__:create_multilabels_from_meters:239 - meters[col].values.astype(float) washer dryer - [0. 0. 0. ... 0. 0. 0.]\n",
      "2022-09-08 12:23:14.602 | INFO     | __main__:create_multilabels_from_meters:229 - Creating multilabels from meter sockets, \n",
      "labels2id[col] ElecMeterID(instance=3, building=3, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=3, building=3, dataset='REDD', appliances=[Appliance(type='sockets', instance=1)])\n",
      "2022-09-08 12:23:14.603 | DEBUG    | __main__:create_multilabels_from_meters:239 - meters[col].values.astype(float) sockets - [0.  1.5 1.5 ... 0.  0.  0. ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold =  10\n",
      "threshold =  10\n",
      "threshold =  10\n",
      "threshold =  10\n",
      "TIMING: Create multilabels from meters 0.19\n",
      "INFO: Reading data from specified meters. \n",
      "-Building: 3\n",
      "-Appliances ['electric furnace', 'CE appliance', 'microwave', 'washer dryer', 'unknown', 'sockets']\n",
      "DEBUG:  read_selected_appliances ['electric furnace', 'CE appliance', 'microwave', 'washer dryer', 'unknown', 'sockets'], 3, 5-17-2011, 5-30-2011, True\n",
      "TIMING: NILMTK select using appliances: 0.03\n",
      "Loading data for meter ElecMeterID(instance=14, building=3, dataset='REDD')     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-08 12:23:16.968 | DEBUG    | __main__:setup_one_building:286 - Length of data of all loaded meters 187200\n",
      "2022-09-08 12:23:16.971 | DEBUG    | __main__:setup_one_building:288 - Length of data of all loaded meters 187200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done loading data all meters for this chunk.\n",
      "TIMING: NILMTK converting specified appliances to dataframe: 2.24\n",
      "DEBUG: Length of data of read_selected_appliances 187200\n",
      "\n",
      "\n",
      "READ_SELECTED_APPLIANCES: \n",
      "                           (10, 3, REDD)  (6, 3, REDD)  (20, 3, REDD)  \\\n",
      "2011-05-17 00:00:00-04:00            0.0           0.0            0.0   \n",
      "2011-05-17 00:00:06-04:00            0.0           0.0            0.0   \n",
      "2011-05-17 00:00:12-04:00            0.0           0.0            0.0   \n",
      "2011-05-17 00:00:18-04:00            0.0           0.0            0.0   \n",
      "2011-05-17 00:00:24-04:00            0.0           0.0            0.0   \n",
      "\n",
      "                           (16, 3, REDD)  (1, 3, REDD)  \\\n",
      "2011-05-17 00:00:00-04:00            0.0           0.0   \n",
      "2011-05-17 00:00:06-04:00            0.0           0.0   \n",
      "2011-05-17 00:00:12-04:00            0.0           0.0   \n",
      "2011-05-17 00:00:18-04:00            0.0           0.0   \n",
      "2011-05-17 00:00:24-04:00            0.0           0.0   \n",
      "\n",
      "                           (((13, 3, REDD), (14, 3, REDD)),)  (3, 3, REDD)  \n",
      "2011-05-17 00:00:00-04:00                                0.0           0.0  \n",
      "2011-05-17 00:00:06-04:00                                0.0           0.0  \n",
      "2011-05-17 00:00:12-04:00                                0.0           0.0  \n",
      "2011-05-17 00:00:18-04:00                                0.0           0.0  \n",
      "2011-05-17 00:00:24-04:00                                0.0           0.0  \n",
      "INFO: Df columns before normalization Index([                      (10, 3, 'REDD'),\n",
      "                              (6, 3, 'REDD'),\n",
      "                             (20, 3, 'REDD'),\n",
      "                             (16, 3, 'REDD'),\n",
      "                              (1, 3, 'REDD'),\n",
      "       (((13, 3, 'REDD'), (14, 3, 'REDD')),),\n",
      "                              (3, 3, 'REDD')],\n",
      "      dtype='object')\n",
      "INFO: Labels before normalization ['Electric furnace', 'CE appliance', 'Unknown', 'Microwave', 'Site meter', 'Washer dryer', 'Sockets']\n",
      "INFO: electric furnace ~ Electric furnace (100%)\n",
      "INFO: CE appliance ~ CE appliance (100%)\n",
      "INFO: unknown ~ Unknown (100%)\n",
      "INFO: microwave ~ Microwave (100%)\n",
      "INFO: washer dryer ~ Washer dryer (100%)\n",
      "INFO: sockets ~ Sockets (100%)\n",
      "INFO: Normalized labels ['electric furnace', 'CE appliance', 'unknown', 'microwave', 'Site meter', 'washer dryer', 'sockets']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-08 12:23:16.972 | INFO     | __main__:create_multilabels_from_meters:229 - Creating multilabels from meter electric furnace, \n",
      "labels2id[col] ElecMeterID(instance=10, building=3, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=10, building=3, dataset='REDD', appliances=[Appliance(type='electric furnace', instance=1)])\n",
      "2022-09-08 12:23:16.974 | DEBUG    | __main__:create_multilabels_from_meters:239 - meters[col].values.astype(float) electric furnace - [0. 0. 0. ... 0. 0. 0.]\n",
      "2022-09-08 12:23:16.980 | INFO     | __main__:create_multilabels_from_meters:229 - Creating multilabels from meter CE appliance, \n",
      "labels2id[col] ElecMeterID(instance=6, building=3, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=6, building=3, dataset='REDD', appliances=[Appliance(type='CE appliance', instance=1)])\n",
      "2022-09-08 12:23:16.982 | DEBUG    | __main__:create_multilabels_from_meters:239 - meters[col].values.astype(float) CE appliance - [0. 0. 0. ... 0. 0. 0.]\n",
      "2022-09-08 12:23:16.986 | INFO     | __main__:create_multilabels_from_meters:229 - Creating multilabels from meter unknown, \n",
      "labels2id[col] ElecMeterID(instance=20, building=3, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=20, building=3, dataset='REDD', appliances=[Appliance(type='unknown', instance=1)])\n",
      "2022-09-08 12:23:16.988 | DEBUG    | __main__:create_multilabels_from_meters:239 - meters[col].values.astype(float) unknown - [0. 0. 0. ... 0. 0. 0.]\n",
      "2022-09-08 12:23:16.993 | INFO     | __main__:create_multilabels_from_meters:229 - Creating multilabels from meter microwave, \n",
      "labels2id[col] ElecMeterID(instance=16, building=3, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=16, building=3, dataset='REDD', appliances=[Appliance(type='microwave', instance=1)])\n",
      "2022-09-08 12:23:16.995 | DEBUG    | __main__:create_multilabels_from_meters:239 - meters[col].values.astype(float) microwave - [0. 0. 0. ... 0. 0. 0.]\n",
      "2022-09-08 12:23:17.000 | INFO     | __main__:create_multilabels_from_meters:229 - Creating multilabels from meter Site meter, \n",
      "labels2id[col] ElecMeterID(instance=1, building=3, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=1, building=3, dataset='REDD', site_meter, appliances=[])\n",
      "2022-09-08 12:23:17.002 | DEBUG    | __main__:create_multilabels_from_meters:237 - Skipping Site meter - [0. 0. 0. ... 0. 0. 0.]\n",
      "2022-09-08 12:23:17.003 | INFO     | __main__:create_multilabels_from_meters:229 - Creating multilabels from meter washer dryer, \n",
      "labels2id[col] MeterGroupID(meters=(ElecMeterID(instance=13, building=3, dataset='REDD'), ElecMeterID(instance=14, building=3, dataset='REDD')))\n",
      "metergroup[labels2id[col]] MeterGroup(meters=\n",
      "  ElecMeter(instance=13, building=3, dataset='REDD', appliances=[Appliance(type='washer dryer', instance=1)])\n",
      "  ElecMeter(instance=14, building=3, dataset='REDD', appliances=[Appliance(type='washer dryer', instance=1)])\n",
      ")\n",
      "2022-09-08 12:23:17.005 | DEBUG    | __main__:create_multilabels_from_meters:239 - meters[col].values.astype(float) washer dryer - [0. 0. 0. ... 0. 0. 0.]\n",
      "2022-09-08 12:23:17.013 | INFO     | __main__:create_multilabels_from_meters:229 - Creating multilabels from meter sockets, \n",
      "labels2id[col] ElecMeterID(instance=3, building=3, dataset='REDD')\n",
      "metergroup[labels2id[col]] ElecMeter(instance=3, building=3, dataset='REDD', appliances=[Appliance(type='sockets', instance=1)])\n",
      "2022-09-08 12:23:17.015 | DEBUG    | __main__:create_multilabels_from_meters:239 - meters[col].values.astype(float) sockets - [0. 0. 0. ... 0. 0. 0.]\n",
      "D:\\Users\\hdmav\\anaconda3\\envs\\nilmtk-env\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass n_neighbors=3 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "D:\\Users\\hdmav\\anaconda3\\envs\\nilmtk-env\\lib\\site-packages\\skmultilearn\\cluster\\random.py:129: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return np.array(label_sets)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Meters that have been loaded (all_df.columns):\n",
      "Index(['electric furnace', 'CE appliance', 'unknown', 'microwave',\n",
      "       'Site meter', 'washer dryer', 'sockets'],\n",
      "      dtype='object')\n",
      "threshold =  40\n",
      "threshold =  10\n",
      "threshold =  10\n",
      "threshold =  10\n",
      "threshold =  10\n",
      "threshold =  10\n",
      "threshold =  10\n",
      "TIMING: Create multilabels from meters 0.05\n",
      "                           electric furnace  CE appliance  unknown  microwave  \\\n",
      "2011-04-16 01:11:24-04:00               0.0           0.0      0.0        0.0   \n",
      "2011-04-16 01:11:30-04:00               5.0         125.5      0.0        2.0   \n",
      "2011-04-16 01:11:36-04:00               4.5         125.5      0.0        2.0   \n",
      "2011-04-16 01:11:42-04:00               5.0         127.0      0.0        2.0   \n",
      "2011-04-16 01:11:48-04:00               5.0         125.0      0.0        2.0   \n",
      "2011-04-16 01:11:54-04:00               5.0         127.0      0.0        2.0   \n",
      "2011-04-16 01:12:00-04:00               4.0         124.0      0.0        2.0   \n",
      "2011-04-16 01:12:06-04:00               4.5         126.0      0.0        2.0   \n",
      "2011-04-16 01:12:12-04:00               5.0         127.0      0.0        2.0   \n",
      "2011-04-16 01:12:18-04:00               5.0         125.0      0.0        2.0   \n",
      "\n",
      "                           Site meter  washer dryer  sockets  \n",
      "2011-04-16 01:11:24-04:00  180.850006           0.0      0.0  \n",
      "2011-04-16 01:11:30-04:00  181.331665           0.0      1.5  \n",
      "2011-04-16 01:11:36-04:00  180.809998           0.0      1.5  \n",
      "2011-04-16 01:11:42-04:00  181.523331           0.0      1.5  \n",
      "2011-04-16 01:11:48-04:00  180.893326           0.0      2.0  \n",
      "2011-04-16 01:11:54-04:00  181.705002           0.0      1.5  \n",
      "2011-04-16 01:12:00-04:00  181.246674           0.0      1.0  \n",
      "2011-04-16 01:12:06-04:00  180.635010           0.0      1.5  \n",
      "2011-04-16 01:12:12-04:00  180.989990           0.0      2.0  \n",
      "2011-04-16 01:12:18-04:00  181.176666           0.0      2.0  \n",
      "INFO: Preprocessing before training...\n",
      "DEBUG: get_site_meter_data\n",
      "DEBUG: dataframe columns: Index(['electric furnace', 'CE appliance', 'unknown', 'microwave',\n",
      "       'Site meter', 'washer dryer', 'sockets'],\n",
      "      dtype='object')\n",
      "DEBUG: type of data <class 'numpy.ndarray'>\n",
      "TIMING: get features time 0.0\n",
      "DEBUG: Features \n",
      " [180.85    181.33167 180.81    181.52333 180.89333 181.705   181.24667\n",
      " 180.63501 180.98999 181.17667]\n",
      "DEBUG: Target \n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]]\n",
      "DEBUG: bucketize_data: Initial shape (187200, 6)\n",
      "DEBUG: n_dims = 2\n",
      "DEBUG: bucketize_data: Shape in batches: (13, 14400, 6)\n",
      "DEBUG: bucketize_target: Shape of array in windows: (13, 14400, 6)\n",
      "DEBUG: bucketize_target: Shape of array after merging windows: (13, 6)\n",
      "DEBUG: bucketize_data: Initial shape (187200,)\n",
      "DEBUG: n_dims = 1\n",
      "DEBUG: bucketize_data: Shape in batches: (13, 14400)\n",
      "type :<class 'numpy.ndarray'>; dtype:float32; ndim=2; shape:(13, 14400)\n",
      "TIMING: reduce dimensions time 0.002995014190673828\n",
      "TIMING: preprocess time 0.00897979736328125\n",
      "INFO: Training...\n",
      "[[180.85     181.33167  180.81     ...   0.         0.         0.      ]\n",
      " [  0.         0.         0.       ... 171.68     170.85666  171.93832 ]\n",
      " [170.88834  170.56999  170.56     ... 117.03833  116.805    117.02167 ]\n",
      " ...\n",
      " [108.55333  107.71833  107.14166  ... 120.863335 120.791664 122.131996]\n",
      " [122.49     122.42     122.225    ...   0.         0.         0.      ]\n",
      " [  0.         0.         0.       ... 123.66     123.409996 123.293335]]\n",
      "TIMING: fit time 8.633734941482544\n",
      "INFO: Preprocessing before testing...\n",
      "DEBUG: get_site_meter_data\n",
      "DEBUG: dataframe columns: Index(['electric furnace', 'CE appliance', 'unknown', 'microwave',\n",
      "       'Site meter', 'washer dryer', 'sockets'],\n",
      "      dtype='object')\n",
      "DEBUG: type of data <class 'numpy.ndarray'>\n",
      "TIMING: get features time 0.00098419189453125\n",
      "DEBUG: Features \n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "DEBUG: Target \n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "DEBUG: bucketize_data: Initial shape (187200, 6)\n",
      "DEBUG: n_dims = 2\n",
      "DEBUG: bucketize_data: Shape in batches: (13, 14400, 6)\n",
      "DEBUG: bucketize_target: Shape of array in windows: (13, 14400, 6)\n",
      "DEBUG: bucketize_target: Shape of array after merging windows: (13, 6)\n",
      "DEBUG: bucketize_data: Initial shape (187200,)\n",
      "DEBUG: n_dims = 1\n",
      "DEBUG: bucketize_data: Shape in batches: (13, 14400)\n",
      "type :<class 'numpy.ndarray'>; dtype:float32; ndim=2; shape:(13, 14400)\n",
      "TIMING: reduce dimensions time 0.001996278762817383\n",
      "TIMING: preprocess time 0.009470701217651367\n",
      "INFO: Testing...\n",
      "TIMING: predictions time 0.02252984046936035\n",
      "INFO: F1 macro 0.48743315508021395\n",
      "INFO: F1 micro 0.6896551724137931\n",
      "TIMING: predictions time 0.030759334564208984\n",
      "INFO: F1 macro 0.37087966499731206\n",
      "INFO: F1 micro 0.475\n"
     ]
    }
   ],
   "source": [
    "def read_REDD(datasource, start, end, sample_period = 6, building = 1) -> Tuple[DataFrame, MeterGroup]:\n",
    "    datasource.set_window(start = start, end = end)\n",
    "    redd_meter = datasource.buildings[building].elec.mains()\n",
    "    \n",
    "    if isinstance(redd_meter, MeterGroup):\n",
    "        mains_metergroup = redd_meter\n",
    "    else:\n",
    "        mains_metergroup = MeterGroup(meters = [redd_meter])\n",
    "    start_time = time.time() if TIMING else None\n",
    "    df = mains_metergroup.dataframe_of_meters(sample_period=sample_period)\n",
    "    df.fillna(0, inplace=True)\n",
    "    return df, mains_metergroup\n",
    "\n",
    "'''\n",
    "\n",
    "DEBUGGING + TIMING\n",
    "\n",
    "'''\n",
    "class NoSiteMeterException(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "class LabelNormalizationError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "def debug(d):\n",
    "    if DEBUG:\n",
    "        print('DEBUG: ' + d)\n",
    "\n",
    "\n",
    "def info(i):\n",
    "    if INFO:\n",
    "        print('INFO: ' + i)\n",
    "\n",
    "\n",
    "def timing(t):\n",
    "    if TIMING:\n",
    "        print('TIMING: ' + t)\n",
    "\n",
    "\n",
    "def debug_mem(message, obj):\n",
    "    if TRACE_MEMORY:\n",
    "        print('MEMORY: {}'.format(message.format(sys.getsizeof(obj) / MB)))\n",
    "\n",
    "\n",
    "def trace_mem(o):\n",
    "    return sys.getsizeof(o) / MB\n",
    "\n",
    "\n",
    "def array_info(ar):\n",
    "    print(f'type :{type(ar)}; dtype:{ar.dtype}; ndim={ar.ndim}; shape:{ar.shape}')\n",
    "\n",
    "\"\"\"\n",
    "CHAOTIC_TOOLKIT\n",
    "\"\"\"\n",
    "\n",
    "def takens_embedding(series: np.ndarray, delay, dimension) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    This function returns the Takens embedding of data with delay into dimension,\n",
    "    delay*dimension must be < len(data)\n",
    "    \"\"\"\n",
    "    if delay * dimension > len(series):\n",
    "        info(f'Not enough data for the given delay ({delay}) and dimension ({dimension}).'\n",
    "             f'\\ndelay * dimension > len(data): {delay * dimension} > {len(series)}')\n",
    "        return series\n",
    "    delay_embedding = np.array([series[0:len(series) - delay * dimension]])\n",
    "    for i in range(1, dimension):\n",
    "        delay_embedding = np.append(delay_embedding,\n",
    "                                    [series[i * delay:len(series) - delay * (dimension - i)]], axis=0)\n",
    "    return delay_embedding\n",
    "\"\"\"\n",
    "TIME SERIES LENGTH\n",
    "\n",
    "\"\"\"\n",
    "class TimeSeriesLength(Enum):\n",
    "    WINDOW_SAMPLE_PERIOD = 'same'\n",
    "    WINDOW_1_MIN = '1m'\n",
    "    WINDOW_5_MINS = '5m'\n",
    "    WINDOW_10_MINS = '10m'\n",
    "    WINDOW_30_MINS = '30m'\n",
    "    WINDOW_1_HOUR = '1h'\n",
    "    WINDOW_2_HOURS = '2h'\n",
    "    WINDOW_4_HOURS = '4h'\n",
    "    WINDOW_8_HOURS = '8h'\n",
    "    WINDOW_1_DAY = '1d'\n",
    "    WINDOW_1_WEEK = '1w'\n",
    "\n",
    "def read_all_meters(dataset, start: str, end: str, sample_period: int = 6, building: int = 1) \\\n",
    "            -> Tuple[DataFrame, MeterGroup]:\n",
    "        \"\"\"\n",
    "        Read the records during the given start and end dates, for all the meters of the given building.\n",
    "        Args:\n",
    "            start (str): The starting date in the format \"{month}-{day of month}-{year}\" e.g. \"05-30-2012\".\n",
    "            end (str): The final date in the format \"{month}-{day of month}-{year}\" e.g. \"08-30-2012\".\n",
    "            sample_period (int): The sample period of the records.\n",
    "            building (int): The building to read the records from.\n",
    "        Returns:\n",
    "            Returns a tuple containing the respective DataFrame and MeterGroup of the data that are read.\n",
    "        \"\"\"\n",
    "        start_time = time.time() if TIMING else None\n",
    "        dataset.set_window(start=start, end=end)\n",
    "        elec = dataset.buildings[building].elec\n",
    "        timing('NILMTK selecting all meters: {}'.format(round(time.time() - start_time, 2)))\n",
    "\n",
    "        start_time = time.time() if TIMING else None\n",
    "        df = elec.dataframe_of_meters(sample_period=sample_period)\n",
    "        timing('NILMTK converting all meters to dataframe: {}'.format(round(time.time() - start_time, 2)))\n",
    "\n",
    "        df.fillna(0, inplace=True)\n",
    "        \n",
    "        return df, elec\n",
    "\n",
    "    \n",
    "def read_selected_appliances( appliances: List, start: str, end: str, sample_period=6, building=1,\n",
    "                                 include_mains=True) -> Tuple[DataFrame, MeterGroup]:\n",
    "        \"\"\"\n",
    "        Loads the data of the specified appliances.\n",
    "        Args:\n",
    "            appliances (List): A list of appliances to read their records.\n",
    "            start (str): The starting date in the format \"{month}-{day of month}-{year}\" e.g. \"05-30-2012\".\n",
    "            end (str): The final date in the format \"{month}-{day of month}-{year}\" e.g. \"08-30-2012\".\n",
    "            sample_period (int): The sample period of the records.\n",
    "            building (int): The building to read the records from.\n",
    "            include_mains (bool): True if should include main meters.\n",
    "        Returns:\n",
    "            Returns a tuple containing the respective DataFrame and MeterGroup of the data that are read.\n",
    "        \"\"\"\n",
    "        debug(f\" read_selected_appliances {appliances}, {building}, {start}, {end}, {include_mains}\")\n",
    "\n",
    "        selected_metergroup = get_selected_metergroup(redd, appliances, building, end, start, include_mains)\n",
    "\n",
    "        start_time = time.time() if TIMING else None\n",
    "        df = selected_metergroup.dataframe_of_meters(sample_period=sample_period)\n",
    "        timing('NILMTK converting specified appliances to dataframe: {}'.format(round(time.time() - start_time, 2)))\n",
    "\n",
    "        debug(f\"Length of data of read_selected_appliances {len(df)}\")\n",
    "        df.fillna(0, inplace=True)\n",
    "        print('\\n')\n",
    "        print('READ_SELECTED_APPLIANCES: ')\n",
    "        print(df.head())\n",
    "        \n",
    "        return df, selected_metergroup\n",
    "\n",
    "def get_selected_metergroup(dataset, appliances, building, end, start, include_mains) -> MeterGroup:\n",
    "        \"\"\"\n",
    "        Gets a MeterGroup with the specified appliances for the given building during the given dates.\n",
    "        Args:\n",
    "            appliances (List): A list of appliances to read their records.\n",
    "            building (int): The building to read the records from.\n",
    "            start (str): The starting date in the format \"{month}-{day of month}-{year}\" e.g. \"05-30-2012\".\n",
    "            end (str): The final date in the format \"{month}-{day of month}-{year}\" e.g. \"08-30-2012\".\n",
    "            include_mains (bool): True if should include main meters.\n",
    "        Returns:\n",
    "            A MeterGroup containing the specified appliances.\n",
    "        \"\"\"\n",
    "        start_time = time.time() if TIMING else None\n",
    "        dataset.set_window(start=start, end=end)\n",
    "        elec = dataset.buildings[building].elec\n",
    "        appliances_with_one_meter = []\n",
    "        appliances_with_more_meters = []\n",
    "        for appliance in appliances:\n",
    "            metergroup = elec.select_using_appliances(type=appliances)\n",
    "            if len(metergroup.meters) > 1:\n",
    "                appliances_with_more_meters.append(appliance)\n",
    "            else:\n",
    "                appliances_with_one_meter.append(appliance)\n",
    "\n",
    "        special_metergroup = None\n",
    "        for appliance in appliances_with_more_meters:\n",
    "            inst = 1\n",
    "            if appliance == 'sockets' and building == 3:\n",
    "                inst = 4\n",
    "            if special_metergroup is None:\n",
    "                special_metergroup = elec.select_using_appliances(type=appliance, instance=inst)\n",
    "            else:\n",
    "                special_metergroup = special_metergroup.union(elec.select_using_appliances(type=appliance, instance=1))\n",
    "\n",
    "        selected_metergroup = elec.select_using_appliances(type=appliances_with_one_meter)\n",
    "        selected_metergroup = selected_metergroup.union(special_metergroup)\n",
    "        if include_mains:\n",
    "            mains_meter = dataset.buildings[building].elec.mains()\n",
    "            if isinstance(mains_meter, MeterGroup):\n",
    "                if len(mains_meter.meters) > 1:\n",
    "                    mains_meter = mains_meter.meters[0]\n",
    "                    mains_metergroup = MeterGroup(meters=[mains_meter])\n",
    "                else:\n",
    "                    mains_metergroup = mains_meter\n",
    "            else:\n",
    "                mains_metergroup = MeterGroup(meters=[mains_meter])\n",
    "            selected_metergroup = selected_metergroup.union(mains_metergroup)\n",
    "        timing('NILMTK select using appliances: {}'.format(round(time.time() - start_time, 2)))\n",
    "        return selected_metergroup\n",
    "    \n",
    "\n",
    "def normalize_columns(df: DataFrame, meter_group: MeterGroup, appliance_names: List[str]) ->Tuple[DataFrame, dict]: \n",
    "    labels = meter_group.get_labels(df.columns)\n",
    "    normalized_labels = []\n",
    "    info(f\"Df columns before normalization {df.columns}\")\n",
    "    info(f\"Labels before normalization {labels}\")\n",
    "\n",
    "    for label in labels:\n",
    "        if label == SITE_METER and SITE_METER not in appliance_names:\n",
    "            normalized_labels.append(SITE_METER)\n",
    "            continue\n",
    "        for name in appliance_names:\n",
    "            ratio = fuzz.ratio(label.lower().replace('electric', \"\").lstrip().rstrip().split()[0],\n",
    "                               name.lower().replace('electric', \"\").lstrip().rstrip().split()[0])\n",
    "            if ratio > 90:\n",
    "                info(f\"{name} ~ {label} ({ratio}%)\")\n",
    "                normalized_labels.append(name)\n",
    "                '''\n",
    "    if len(normalized_labels) != len(labels):\n",
    "        debug(f\"len(normalized_labels) {len(normalized_labels)} != len(labels) {len(labels)}\")\n",
    "        raise LabelNormalizationError()\n",
    "        '''\n",
    "    label2id = {l: i for l, i in zip(normalized_labels, df.columns)}\n",
    "    df.columns = normalized_labels\n",
    "    info(f\"Normalized labels {normalized_labels}\")\n",
    "    return df, label2id\n",
    "'''\n",
    "CREATE MULTILABELS FROM METERS\n",
    "'''\n",
    "\n",
    "def create_multilabels_from_meters(meters: DataFrame, meter_group: MeterGroup, labels2id: dict) -> DataFrame:\n",
    "    start_time = time.time() if TIMING else None\n",
    "    labels = dict()\n",
    "    for col in meters.columns:\n",
    "        loguru.logger.info(f\"Creating multilabels from meter {col}, \"\n",
    "                           f\"\\nlabels2id[col] {labels2id[col]}\"\n",
    "                           f\"\\nmetergroup[labels2id[col]] {meter_group[labels2id[col]]}\")\n",
    "        meter = meter_group[labels2id[col]]\n",
    "        threshold = meter.on_power_threshold()\n",
    "        print(\"threshold = \", threshold)\n",
    "        vals = meters[col].values.astype(float)\n",
    "        if vals is None or col == SITE_METER:\n",
    "            loguru.logger.debug(f\"Skipping {col} - {vals}\")\n",
    "            continue\n",
    "        loguru.logger.debug(f\"meters[col].values.astype(float) {col} - {vals}\")\n",
    "        labels[col] = create_labels(vals, threshold)\n",
    "    timing('Create multilabels from meters {}'.format(round(time.time() - start_time, 2)))\n",
    "    return DataFrame(labels)\n",
    "\n",
    "\n",
    "\n",
    "@njit(parallel=True)\n",
    "def create_labels(array, threshold):\n",
    "    res = np.empty(array.shape)\n",
    "    for i in range(len(array)):\n",
    "        if array[i] >= threshold:\n",
    "            res[i] = 1\n",
    "        else:\n",
    "            res[i] = 0\n",
    "    return list(res)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "SET UP 1 BUILDING (HOUSE 1)\n",
    "'''\n",
    "def setup_one_building(appliances, datasource, building, start_date, end_date,\n",
    "                           sample_period) -> (pd.DataFrame, MeterGroup, Dict, Dict):\n",
    "        \"\"\"\n",
    "        Setup and load the data using one building.\n",
    "        Args:\n",
    "            appliances (List): The appliances that will be recongized.\n",
    "            datasource (Datasource): The Datasource that will be used to load energy data.\n",
    "            building (int): The building that is used.\n",
    "            start_date (str): Start date of the data that will be selected for each building.\n",
    "            end_date (str): End date of the data that will be selected for each building.\n",
    "            sample_period (int): The sampling frequency.\n",
    "        Returns:\n",
    "        \"\"\"\n",
    "        if appliances:\n",
    "            info(f'Reading data from specified meters. \\n-Building: {building}\\n-Appliances {appliances}')\n",
    "            all_df, metergroup = read_selected_appliances(appliances=appliances, start=start_date,\n",
    "                                                                     end=end_date,\n",
    "                                                                     sample_period=sample_period, building=building)\n",
    "\n",
    "        else:\n",
    "            info('Reading data from all meters...')\n",
    "            all_df, metergroup = read_all_meters(redd, start_date, end_date,\n",
    "                                                            building=building,\n",
    "                                                            sample_period=sample_period)\n",
    "\n",
    "        loguru.logger.debug(f\"Length of data of all loaded meters {len(all_df)}\")\n",
    "        all_df, label2id = normalize_columns(all_df, metergroup, appliances)\n",
    "        loguru.logger.debug(f\"Length of data of all loaded meters {len(all_df)}\")\n",
    "        info('Meters that have been loaded (all_df.columns):\\n' + str(all_df.columns))\n",
    "        return all_df, metergroup, label2id\n",
    "\n",
    "\n",
    "def get_no_samples_per_min():\n",
    "    return 60/6\n",
    "\n",
    "def get_no_samples_per_hour():\n",
    "    return get_no_samples_per_min() * 60\n",
    "\n",
    "def get_no_samples_per_day():\n",
    "    return get_no_samples_per_hour() * 24\n",
    "\n",
    "def get_window(dt: TimeSeriesLength) -> int:\n",
    "    choices = {TimeSeriesLength.WINDOW_SAMPLE_PERIOD: 1,\n",
    "              TimeSeriesLength.WINDOW_1_MIN: get_no_samples_per_min(),\n",
    "              TimeSeriesLength.WINDOW_5_MINS: get_no_samples_per_min() * 5,\n",
    "              TimeSeriesLength.WINDOW_10_MINS: get_no_samples_per_min() * 10,\n",
    "              TimeSeriesLength.WINDOW_30_MINS: get_no_samples_per_min() * 30,\n",
    "              TimeSeriesLength.WINDOW_1_HOUR: get_no_samples_per_hour(),\n",
    "              TimeSeriesLength.WINDOW_2_HOURS: get_no_samples_per_hour() * 2,\n",
    "              TimeSeriesLength.WINDOW_4_HOURS: get_no_samples_per_hour() * 4,\n",
    "              TimeSeriesLength.WINDOW_8_HOURS: get_no_samples_per_hour() * 8,\n",
    "              TimeSeriesLength.WINDOW_1_DAY: get_no_samples_per_day(),\n",
    "              TimeSeriesLength.WINDOW_1_WEEK: get_no_samples_per_day() * 7\n",
    "              }\n",
    "    return int(choices.get(dt, 1))\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def transform(series: np.ndarray, sample_period: int = 6, dimension: int = 6, delay_in_seconds: int = 30) -> list:\n",
    "    delay_items = int(delay_in_seconds / sample_period)\n",
    "    window_size = delay_items * dimension\n",
    "    num_of_segments = int(len(series)/ window_size)\n",
    "    delay_embeddings = []\n",
    "    for i in range(num_of_segments):\n",
    "        segment = series[i * window_size:(i+1) * window_size]\n",
    "        embedding = takens_embedding(segment, delay_items, dimension)\n",
    "        delay_embeddings.append(embedding)\n",
    "    return delay_embeddings\n",
    "\n",
    "def approximate(series_in_segments: np.ndarray, sample_period: int = 6, window: int = 1, should_fit = False, dimension: int = 6, delay_in_seconds: int = 30) -> np.ndarray:\n",
    "    delay_items = int(delay_in_seconds / sample_period)\n",
    "    window_size = delay_items * dimension\n",
    "    array_info(series_in_segments)\n",
    "    if window_size > len(series_in_segments[0]):\n",
    "        raise Exception(f'Not enough data for the given delay({delay_in_seconds} seconds) and dimension ({dimension}).'\n",
    "                       f'\\ndelayitems * dimension > len(data): {window_size} > {len(series_in_segments[0])}')\n",
    "    if window_size == len(series_in_segments[0]):\n",
    "        info(f\"delay embeddings equavelent to the length of each segment\"\n",
    "            f\"{window_size} == {len(series_in_segments[0])}\")\n",
    "    delay_embeddings = []\n",
    "    for segment in series_in_segments:\n",
    "        embedding = takens_embedding(segment, delay_items, dimension)\n",
    "        delay_embeddings.append(embedding)\n",
    "    return np.asarray(delay_embeddings)\n",
    "\n",
    "        \n",
    "def get_multilabels(labels_df: DataFrame, appliances: List = None) -> DataFrame:\n",
    "    if appliances is None:\n",
    "        return labels_df\n",
    "    else:\n",
    "        return labels_df[appliances]\n",
    "\n",
    "def get_site_meter_data(df: DataFrame) -> np.ndarray:\n",
    "    debug('get_site_meter_data')\n",
    "    debug(f'dataframe columns: {df.columns}')\n",
    "    for col in df.columns:\n",
    "        if SITE_METER in col:\n",
    "            return df[col].values\n",
    "    raise NoSiteMeterException(\"Couldn't find site meter\")\n",
    "        \n",
    "        \n",
    "def get_features(data_df: DataFrame) -> List:\n",
    "    data = get_site_meter_data(data_df)\n",
    "    debug(f'type of data {type(data)}')\n",
    "    #data = transform(data)\n",
    "    return data\n",
    "\n",
    "def reduce_dimensions(data_in_batches: np.ndarray, window: int, target: np.ndarray,should_fit: bool = False):\n",
    "    squeezed_seq = approximate(data_in_batches, window, target, should_fit)\n",
    "    return squeezed_seq\n",
    "\n",
    "def bucketize_data(data: np.ndarray, window: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    It segments the time series grouping it into batches. Its segment is of size equal to the window.\n",
    "    Args:\n",
    "        data (ndarray): The given time series.\n",
    "        window (int): The size of the segments.\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    debug('bucketize_data: Initial shape {}'.format(data.shape))\n",
    "    n_dims = len(data.shape)\n",
    "    debug(f'n_dims = {n_dims}')\n",
    "    if n_dims == 1:\n",
    "        seq_in_batches = np.reshape(data, (int(len(data) / window), window))\n",
    "    elif n_dims == 2:\n",
    "        seq_in_batches = np.reshape(data, (int(len(data) / window), window, data.shape[1]))\n",
    "    else:\n",
    "        raise Exception('Invalid number of dimensions {}.'.format(n_dims))\n",
    "    debug('bucketize_data: Shape in batches: {}'.format(seq_in_batches.shape))\n",
    "    return seq_in_batches\n",
    "\n",
    "def bucketize_target(target: np.ndarray, window: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Creates target data according to the lenght of the window of the segmented data.\n",
    "    Args:\n",
    "        target (ndarray): Target data with the original size.\n",
    "        window (int): The length of window that will be used to create the corresponding labels.\n",
    "    Returns:\n",
    "        The target data for the new bucketized time series.\n",
    "    \"\"\"\n",
    "    target_in_batches = bucketize_data(target, window)\n",
    "    any_multilabel = np.any(target_in_batches, axis=1)\n",
    "    debug('bucketize_target: Shape of array in windows: {}'.format(target_in_batches.shape))\n",
    "    debug('bucketize_target: Shape of array after merging windows: {}'.format(any_multilabel.shape))\n",
    "    return any_multilabel\n",
    "\n",
    "\n",
    "def preprocess(data_df, labels_df, appliances,should_fit: bool = True):\n",
    "    start_time = time.time()\n",
    "    data = get_features(data_df)\n",
    "    get_features_time = time.time() - start_time\n",
    "    timing(f\"get features time {get_features_time}\")\n",
    "    debug(f\"Features \\n {data[:10]}\")\n",
    "    target = get_multilabels(labels_df,appliances)\n",
    "    target = np.array(target.values)\n",
    "    debug(f\"Target \\n {target[:10]}\")\n",
    "    window = get_window(TimeSeriesLength.WINDOW_1_DAY)\n",
    "    rem = len(data) % window\n",
    "    if rem>0:\n",
    "        data = data[:-rem]\n",
    "        target = target[:-rem]\n",
    "    target = bucketize_target(target, window)\n",
    "    data = bucketize_data(data, window)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    data = reduce_dimensions(data,window,target,should_fit)\n",
    "    reduce_dimensions_time = time.time() - start_time\n",
    "    timing(f\"reduce dimensions time {reduce_dimensions_time}\")\n",
    "    \n",
    "    return data, target\n",
    "'''\n",
    "\n",
    "EXPERIMENT\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "def setup_train_data(datasource, building: int, year: str, start_date: str, end_date: str, sample_period: int, appliances: List):\n",
    "    train_df, train_metergroup,train_label2id = setup_one_building(appliances,datasource,building,start_date,end_date,sample_period)\n",
    "    train_labels_df = create_multilabels_from_meters(train_df, train_metergroup,train_label2id)\n",
    "    return train_df, train_labels_df\n",
    "\n",
    "\n",
    "def setup_test_data(datasource, building: int, year: str, start_date: str, end_date: str, sample_period: int, appliances: List):\n",
    "    test_df, test_metergroup,test_label2id = setup_one_building(appliances,datasource,building,start_date,end_date,sample_period)\n",
    "    test_labels_df = create_multilabels_from_meters(test_df, test_metergroup,test_label2id)\n",
    "    return test_df, test_labels_df\n",
    "\n",
    "\n",
    "\n",
    "def train(appliances: list, train_df,train_labels_df, raw_data: bool = False):\n",
    "    info(\"Preprocessing before training...\")\n",
    "    start_time = time.time()\n",
    "    data, target = preprocess(train_df, train_labels_df, appliances)\n",
    "    preprocess_time = time.time() - start_time\n",
    "    timing(f\"preprocess time {preprocess_time}\")\n",
    "    \n",
    "    if len(data.shape) == 3:\n",
    "        data = np.reshape(data, (data.shape[0], data.shape[1] * data.shape[2]))\n",
    "        \n",
    "        info(\"Training...\")\n",
    "        start_time = time.time()\n",
    "        print(data[:10])\n",
    "        classifier.fit(data,target)\n",
    "        rakel.fit(data,target)\n",
    "        fit_time = time.time() - start_time\n",
    "        timing(f\"fit time {fit_time}\")\n",
    "        return preprocess_time, fit_time\n",
    "    \n",
    "def test(appliances: list, test_df, test_labels_df, raw_data: bool = False):\n",
    "    if test_df is None or test_labels_df is None:\n",
    "        raise(Exception('Test data or test target is None'))\n",
    "    info(\"Preprocessing before testing...\")\n",
    "    start_time = time.time()\n",
    "    data, target = preprocess(test_df, test_labels_df, appliances)\n",
    "    preprocess_time = time.time() - start_time\n",
    "    timing(f\"preprocess time {preprocess_time}\")\n",
    "    if len(data.shape) == 3:\n",
    "        data = np.reshape(data, (data.shape[0], data.shape[1] * data.shape[2]))\n",
    "    info(\"Testing...\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    predictions = classifier.predict(data)\n",
    "    predictions_time = time.time() - start_time\n",
    "    timing(f\"predictions time {predictions_time}\")\n",
    "\n",
    "    micro = f1_score(target, predictions, average='micro')\n",
    "    macro = f1_score(target, predictions, average='macro')\n",
    "    info('F1 macro {}'.format(macro))\n",
    "    info('F1 micro {}'.format(micro))\n",
    "    \n",
    "    start_time = time.time()\n",
    "    predictions = rakel.predict(data)\n",
    "    predictions_time = time.time() - start_time\n",
    "    timing(f\"predictions time {predictions_time}\")\n",
    "\n",
    "    micro = f1_score(target, predictions, average='micro')\n",
    "    macro = f1_score(target, predictions, average='macro')\n",
    "    info('F1 macro {}'.format(macro))\n",
    "    info('F1 micro {}'.format(micro))\n",
    "    #report = classification_report(target, predictions, target_names=appliances, output_dict=True)\n",
    "        # confusion_matrix = multilabel_confusion_matrix(y_true=target, y_pred=predictions.toarray())\n",
    "        # confusion_matrix = None\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "year = '2011'\n",
    "month_end = '8'\n",
    "month_start = '1'\n",
    "end_date = \"{}-30-{}\".format(month_end, year)\n",
    "start_date = \"{}-1-{}\".format(month_start, year)\n",
    "sample_period = 6\n",
    "df_mains, metergroup = read_REDD(redd, start=None, end=None, sample_period=sample_period, building=1)\n",
    "# print(df_mains[(1, 1, 'REDD')].values)\n",
    "print(df_mains.describe())\n",
    "figure = df_mains.plot().get_figure()\n",
    "'''\n",
    "redd = DataSet(r'D:\\Users\\hdmav\\jupyter\\multilabel-class\\REDD\\redd.h5')\n",
    "appliances = ['electric furnace', 'CE appliance', 'microwave', 'washer dryer', 'unknown', 'sockets']\n",
    "building = 3\n",
    "sample_period = 6\n",
    "\n",
    "redd3_train_year_start = '2011'\n",
    "redd3_train_year_end = '2011'\n",
    "redd3_train_month_end = '4'\n",
    "redd3_train_month_start = '4'\n",
    "redd3_train_end_date = \"{}-30-{}\".format(redd3_train_month_end, redd3_train_year_end)\n",
    "redd3_train_start_date = \"{}-16-{}\".format(redd3_train_month_start, redd3_train_year_start)\n",
    "\n",
    "redd3_test_year_start = '2011'\n",
    "redd3_test_year_end = '2011'\n",
    "redd3_test_month_end = '5'\n",
    "redd3_test_month_start = '5'\n",
    "redd3_test_end_date = \"{}-30-{}\".format(redd1_test_month_end, redd1_test_year_end)\n",
    "redd3_test_start_date = \"{}-17-{}\".format(redd1_test_month_start, redd1_test_year_start)\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    train_df, train_labels_df = setup_train_data(redd, building, redd3_train_year_start, redd3_train_start_date, redd3_train_end_date, sample_period, appliances) \n",
    "    test_df, test_labels_df = setup_test_data(redd, building, redd3_test_year_end, redd3_test_start_date, redd3_test_end_date, sample_period, appliances) \n",
    "    print(train_df[:10])\n",
    "    train(appliances, train_df, train_labels_df)\n",
    "    test(appliances,test_df,test_labels_df)\n",
    "\n",
    "    \n",
    "    \n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf6735c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c59a9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d41856",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nilmtk-env]",
   "language": "python",
   "name": "conda-env-nilmtk-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
